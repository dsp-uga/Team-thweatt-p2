# -*- coding: utf-8 -*-
"""OpticalFlow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WqQAGlqRX1gBlT70hAyPzHi3ARnEowDS
"""

import cv2
import numpy as np
import os
import math
import pandas as pd
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn import preprocessing
import scipy.misc
import time
import numpy as np
from sklearn.ensemble import BaggingClassifier, RandomForestClassifier
from sklearn import datasets
from sklearn.multiclass import OneVsRestClassifier
from sklearn.svm import SVC

dir = "/Users/hemanth/Desktop/MSAI/DataSciencePracticum/Projects/p2/"
train_folder = dir+"pp_data_train"
test_folder = dir+"pp_data_test"
masks_folder = dir+"pp_masks"
pics = 30

def highVariance(imgs):
    imgs_shape = np.stack(imgs)
    var_imgs = np.var(imgs_shape,axis = 0)
    var_flat = var_imgs.flatten()
    var_flat_scaled = np.interp(var_flat, (var_flat.min(), var_flat.max()), (0,1))
    return var_flat_scaled


def get_pp_images(train_folder,masks_folder):
    folders = [f for f in os.listdir(train_folder) if not f.startswith('.')]
    X_train = []
    y_train = []
    for folder in folders:
        for file in os.listdir(train_folder+'/'+folder):
            X_train.append(np.load(train_folder+'/'+folder+'/'+file))
        mask = np.load(masks_folder+'/'+folder+'.npy')
        mask[np.where(mask != 2)] = 0
        y_train.append(mask)
    return X_train,y_train


def get_pp_images_test(test_folder):
    folders = [f for f in os.listdir(test_folder) if not f.startswith('.')]
    X_test = []
    y_test = []
    for folder in folders:
        for file in os.listdir(test_folder+'/'+folder):
            X_test.append(np.load(test_folder+'/'+folder+'/'+file))
        y_test.append(folder)
    return X_test,y_test

def getFeaturesTrain(X_train):
    train_dict = {'angle' : [],'mag' : [],'intnC': [],'fftC':[],'varC': [],'mask' : []}
    train_df = pd.DataFrame(train_dict)
    
    #check for across 30 frames relative to one-another instead of relative to first img
    for j in range(len(X_train)):
        currentTrain = X_train[j]
        currentMask = y_train[j]
        
        prvs = currentTrain[0]
        
        for i in range(1,len(currentTrain)):
            next = currentTrain[i]
            flow = cv2.calcOpticalFlowFarneback(prvs, next,None, 0.5, 3, 15, 3, 5, 1.2, 0)
            mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])
            angle = ang*180/np.pi/2
            magn = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)
            
            dft = cv2.dft(np.float32(next),flags = cv2.DFT_COMPLEX_OUTPUT)
            dft_shift = np.fft.fftshift(dft)
            magnitude_spectrum = cv2.magnitude(dft_shift[:,:,0],dft_shift[:,:,1])
            magnitude_spectrum_n = cv2.normalize(magnitude_spectrum,None,0,255,cv2.NORM_MINMAX)

            if(i == 1):
                mags = magn
                angs = angle
                ffts = magnitude_spectrum_n
            else:
                mags = np.sum([mags,magn],axis = 0)
                angs = np.mean([angs,angle],axis = 0)
                ffts = np.mean([ffts,magnitude_spectrum_n],axis = 0)

        
        angleC = angs.flatten()
        magnC = mags.flatten()
        intnC = prvs.flatten()
        fftC = ffts.flatten()
        varC = highVariance(currentTrain)
        maskC = currentMask.flatten()
        
        dict_temp = {'angle' : angleC,'mag' : magnC,'intnC': intnC,'fftC': fftC,'varC': varC,'mask' : maskC}
        df = pd.DataFrame(dict_temp)
        df_2 = df[df['mask']==2]
        df_0 = df[df['mask']==0]
        #cilia_count = (df_2.shape[0])/df.shape[0]
        #cell_count = (df_1.shape[0])/df.shape[0]
        #back_count = (df_0.shape[0])/df.shape[0]
        if(df_2.shape[0] != 0):
            df_cilia = df_2.sample(n = math.ceil(0.75*df_2.shape[0]))
        else:
            df_cilia = df_2
        if(df_0.shape[0] != 0):
            df_back = df_0.sample(n = math.ceil(0.25*df_0.shape[0]))
        else:
            df_back = df_0
        train_df = pd.concat([train_df,df_cilia,df_back])
    return(train_df)
    
def getFeaturesTest(X_test): 
    currentTrain = X_test
    #currentMask = y_train[j]
    
    prvs = currentTrain[0]
    
    for i in range(1,len(currentTrain)):
        next = currentTrain[i]
        flow = cv2.calcOpticalFlowFarneback(prvs, next,None, 0.5, 3, 15, 3, 5, 1.2, 0)
        mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])
        angle = ang*180/np.pi/2
        magn = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)
        
        dft = cv2.dft(np.float32(next),flags = cv2.DFT_COMPLEX_OUTPUT)
        dft_shift = np.fft.fftshift(dft)
        magnitude_spectrum = cv2.magnitude(dft_shift[:,:,0],dft_shift[:,:,1])
        magnitude_spectrum_n = cv2.normalize(magnitude_spectrum,None,0,255,cv2.NORM_MINMAX)

        if(i == 1):
            mags = magn
            angs = angle
            ffts = magnitude_spectrum_n
        else:
            mags = np.sum([mags,magn],axis = 0)
            angs = np.mean([angs,angle],axis = 0)
            ffts = np.mean([ffts,magnitude_spectrum_n],axis = 0)
    
    angleC = angs.flatten()
    magnC = mags.flatten()
    intnC = prvs.flatten()
    fftC = ffts.flatten()
    varC = highVariance(currentTrain)
        
    #maskC = currentMask.flatten()
    
    dict_temp = {'angle' : angleC,'mag' : magnC,'intnC': intnC,'fftC': fftC,'varC': varC}
    
    test_df = pd.DataFrame(dict_temp)
    return(test_df)


#Reading train and masks
if os.path.exists(train_folder) and os.path.exists(masks_folder):
    X_train,y_train = get_pp_images(train_folder,masks_folder)
else:
    print('Pre-processed training/masks set not available')
    
#Reading test images
if os.path.exists(test_folder):
    X_test,test_names = get_pp_images_test(test_folder)
else:
    print('Pre-processed testing set not available')

ntrain = len([f for f in os.listdir(train_folder) if not f.startswith('.')])
ntest = len([f for f in os.listdir(test_folder) if not f.startswith('.')])


X_train = np.array(X_train)
X_train = np.reshape(X_train,(ntrain,pics))

y_train = np.array(y_train)

X_test = np.array(X_test)
X_test = np.reshape(X_test,(ntest,pics))

train_DF = getFeaturesTrain(X_train)

#train_2 = train_DF[train_DF['mask']==2]
#pd.set_option('display.max_colwidth', 100)
#train_2['fftC'].describe()


train_DF.to_pickle(dir+'training_df/sum30_finfeat_binary.pkl')

train_DF = pd.read_pickle(dir+'training_df/sum30_morefeat_binary.pkl')

train_DF.to_csv(dir+'training_df/sum30_morefeat_binary.csv',index=False)

train_DF['mask'] = train_DF['mask'].astype('category')

x = train_DF[['angle','mag','intnC','fftC','varC']]
X = train_DF[['angle','mag','intnC']]
y = train_DF['mask']

#https://stackoverflow.com/questions/31681373/making-svm-run-faster-in-python
n_estimators = 10
start = time.time()
clf = BaggingClassifier(SVC(kernel='linear', probability=True, class_weight=None), max_samples=1.0 / n_estimators, n_estimators=n_estimators,n_jobs = -1,verbose = 1)
clf.fit(X, y)
end = time.time()
print("Bagging SVC", end - start, clf.score(X,y))
y_pred_train = clf.predict_proba(X)


from sklearn.neural_network import MLPClassifier
clf = MLPClassifier(hidden_layer_sizes=(10,20,10), max_iter=50, alpha=0.0001,solver='adam', verbose=10,  random_state=21,tol=0.000000001)
clf.fit(x, y)



clf = RandomForestClassifier(n_estimators=100, max_depth=10,random_state=0,verbose = 1,n_jobs = -1)
clf_fit = clf.fit(x, y) 

from sklearn.metrics import confusion_matrix
y_pred_train = clf_fit.predict_proba(x)
y_pred_train = clf.predict_proba(x)
#y_pred_train = clf_fit.predict(x)

    
#df['id_label'] = df['col_1'].apply(ifef)
#
#dfx = pd.DataFrame(y_pred_train)
#dfx = dfx.rename(columns={0: 'back',1:'cilia'})
#df['id_label'] = df['col_1'].apply(ifef)

#dfx_2 = dfx[dfx['cilia'] > 0.6]

y_pred_cut = np.where(y_pred_train[:,2]>0.25, 2,0)
y_pred_cut = np.where(y_pred_train[:,1]>0.25, 2,0)

#abc = y_pred_train[:,1]

confusion_matrix(y, y_pred_cut)
confusion_matrix(y, y_pred_train)

#https://github.com/Witsung/SVM-Fruit-Image-Classifier/blob/master/main.py

#clf = SVC(kernel = 'linear',C = 1.0)
clf = SVC(kernel='rbf', C=1.0, gamma=0.1)
clf = SVC(C=100.0, cache_size=7000, class_weight='balanced', degree=3,gamma=0.10000000000000001, kernel='rbf', probability=True)

X_scaled = preprocessing.scale(x)
clf = SVC(C=100.0, cache_size=7000, class_weight='balanced',gamma=0.10000000000000001, kernel='linear', probability=True)
clf_fit = clf.fit(X_scaled, y)

if not os.path.isdir(dir+"output"):
    os.mkdir(dir+"output")
    
for i in range(len(X_test)):
    print(i)
    currentTest = X_test[i]
    testName = test_names[i]
    dimX = currentTest[1].shape[0]
    dimY = currentTest[1].shape[1]
    test_DF = getFeaturesTest(currentTest)
    y_pred = clf_fit.predict_proba(test_DF[['angle','mag','intnC','fftC','varC']])
    y_pred_cut = np.where(y_pred[:,1]>0.45, 2,0)
    pred_img = np.reshape(y_pred_cut,(dimX,dimY)).astype('uint8')
    scipy.misc.toimage(pred_img, cmin=0.0, cmax=...).save(dir+'output/'+testName+'.png')

